---
title: Technology for Monitoring & Evaluation
permalink: technology-for-monitoring-and-evaluation/
description: The Technology for Monitoring and Evaluation anchor area page as part of the Peace Corps ICT4D Playbook.
---

<div class="image"><img src="/img/m-and-e-icon.svg" style="height:100px;"><!-- </div> -->

<p class="lead">Volunteers use mobile technologies to monitor their projects, collect feedback, and evaluate their work, and scale their successes.</p>

Volunteer activities include:

- Using mobile phones to capture survey data while in the field.
- Training local staff and counterparts on mobile data collection.
- Promoting best practices in mobile data—including privacy and security awareness and data responsibility.
- They train their communities on data-driven decision-making, analysis, and reporting.



# Overview

Mobile data collection allows Peace Corps Volunteers to adopt a real-time, feedback-oriented, documented approach to their projects and activities. It enables our service to be oriented towards impact, and for our Volunteers to become better development professionals. These are just a few of the ways that we see Volunteers using ICTs in these ways:

- **Diagnosis**. ICTs help bring new voices and broader participation into program diagnosis and enable a wider range of inputs at a reduced cost. They enable evaluators to better manage and pull possible trends out of large data sets.  

- **Planning**. ICTs can help achieve greater inclusion in planning processes. New technologies make it easier to compare and visualize data sets and to analyze data based on location so that resources can be better allocated. Data can also be aggregated more quickly and shared at various levels to improve participation in the planning process and support better decisions. New software tools can enhance the development and management of theories of change.

- **Implementation and monitoring**. ICTs allow for the collection of real-time data on participant experiences, behaviors and attitudes, meaning that analysis can be conducted early on in the process and course corrections can be made to improve interventions and outcomes. Direct feedback from program participants is also possible through new ICTs, which can allow for greater transparency and accountability.

- **Evaluation**. ICTs can increase the voice of vulnerable and underrepresented groups and broaden the types and volume of data that can be collected, combined, compared and analyzed. New technologies may be able to help overcome challenges and constraints such as sample bias and poor data quality, and they can improve the understanding of complex sets of behavior and data.

- **Reporting, sharing and learning**. ICTs enable wider circulation of evaluative learning, interactive sharing and greater public engagement with evaluation findings.



# Snapshot

- Download the [2015 Technology for M&E Snapshot]()

- Snapshot trends coming soon...



# Learn More

*The inclusion of a resource or organization here is for educational purposes only and does not reflect official Peace Corps policy or endorsements.*


### Shared Drive Resources

Go directly to the often-updated collection of documents, PDFs, and other media at the [shared drive](http://bit.ly/peacecorpsict4dshareddrive) -- particularly the [technology for monitoring and evaluation](https://drive.google.com/open?id=0B3_92O4iu-M3QlNScnB0RG9yVnc) folder (embedded below).

<iframe src="https://drive.google.com/embeddedfolderview?id=0B3_92O4iu-M3QlNScnB0RG9yVnc#list" width="800" height="600" frameborder="0"></iframe>



### Readings

- [Does Technology Make Monitoring and Evaluation More or Less Efficient? - ICT Works](http://www.ictworks.org/2015/06/29/does-technology-make-monitoring-and-evaluation-more-or-less-efficient/)

> ICT has the potential to transform the efficiency and usefulness of data collection, as well as boosting organizational confidence in data collected through M&E systems. But it also has the potential to create inefficiencies if applied in inefficient operations where human capacity and technological infrastructure is low.

- [3 Systematic Reasons Why M&E Technology Projects Fail - ICT Works](http://www.ictworks.org/2015/06/26/why-me-technology-fails-too-complex-too-costly-too-siloed/) -- Complexity, cost, and interoperability.

- [Evaluating Tech Tools](http://www.ictworks.org/2015/02/11/3-phases-and-3-questions-in-evaluating-technology-tools-for-better-me/) -- Separate monitoring of ICT tools/platforms into three phases: rollout, implementation, and long-term use, adoption, and sustainability. Also answer three evaluative questions: What is the role of technology in organizational processes and is there ease of adoption among those using it, What is the role of tech in decision-making and program outcomes, and What level and type of tech support is provided or needed?

- [Case studies as a tool for sector learning](http://algoso.org/2014/12/16/case-studies-as-a-tool-for-sector-learning/) -- Exploring these questions -- How does a sector learn? What drives totally new practices, how do we verify and validate lessons from them, and which channels and mechanisms lead to their dissemination and iteration?

- [Four principles for Theories of Change in global development - Comment - Overseas Development Institute (ODI)](http://www.odi.org/comment/9882-four-principles-theories-change-global-development)

	1. Focus on process
	2. Prioritize learning
	3. Be locally led, and
	4. Think compass not map.

- [The 11 Things Everyone Should Know About Piloting a Survey - Knowledge Management for Development](http://www.km4dev.org/profiles/blogs/the-11-things-everyone-should-know-about-piloting-a-survey)

	1. Ensure that you have done enough secondary research
	2. Take feedback from your organization
	3. Choose a representative sample for piloting
	4. Pilot the survey in the correct medium
	5. Integrate the pilot with your training
	6. Question the survey questions
	7. Examine the data being collected
	8. Pilot all aspects of the survey
	9. Collect feedback from everyone
	10. Never re-pilot the same version of a survey
	11. Be thoughtful about what changes to make

- [E4C Webinars l Mobile Data Collection: A New Frontier of Tech4Dev Research - YouTube](https://www.youtube.com/watch?v=2BoPJP-3zFw) -- Webinar hosted by [Engineers for Change]() that explores: the challenges of data collection in field research; how data collection has been leveraged to collect more timely, accurate, and reliable data; and where the data collection field is headed.

- [7 Tips for Better Digital M&E in Sustainable Development - ICT Works](http://www.ictworks.org/2015/12/21/7-tips-for-better-digital-me-in-sustainable-development/)

	1. Involve Everybody
	2. Simple Technology
	3. Free to Use and Incentives
	4. Match Literacy and Languages
	5. KISS: Keep It Short and Simple
	6. Check Early For Bad Data
	7. Opt-in and Opt-out

- [Do ICTs Make Evaluation More Inclusive Or More Extractive? - ICT Works](http://www.ictworks.org/2016/01/04/do-icts-make-evaluation-more-inclusive-or-more-extractive/) -- Great and short thought-piece that explores the best aspects of M&E while also addressing a concern that they can do more harm than good when done poorly.

- [Community Mapping & Micro Planning Project For 264 Villages Across Vijayawada - SocialCops Blog](http://blog.socialcops.com/portfolio/community-mapping-micro-planning-project-264-villages-across-vijayawada) -- Great example of a case study formatted discussion from India.



### Certifications and Training

- [Get Your Degree in M&E Tech with TechChange - ICT Works](https://www.techchange.org/online-courses/technology-for-monitoring-and-evaluation/?) -- This four week online certificate course will focus on building skills and strategies to better collect, manage, analyze and visualize data using a variety of tech tools.  It will feature live interactive guest expert presentations with leading M&E practitioners, software developers, and data scientists. It will also include a unique hands-on learning environment with animated videos, technology demos, practical activities, networking events, immersive simulations and more.

- [CommCare Learning Tracks](https://confluence.dimagi.com/display/commcarepublic/CommCare+Learning+Tracks) -- For use with Dimagi's CommCare platform specifically (though the lessons can be generalized) -- "We have organized CommCare learning resources into modules on topics like Form Building and Mobile Worker Management. You can think of each of these as a "course." Once you complete a course you should be able to do most tasks associated with the module topic. Those modules are then organized into different tracks that build to more complex tasks. These tracks will guide you to acquire a specific skill-set."



### Organizations

- [Evidence Gap Maps](http://www.3ieimpact.org/en/evidence/gap-maps/) -- Evidence gap maps (EGMs) consolidate what we know about what works in particular development sectors or thematic areas. 3ie’s EGMs identify evidence from systematic reviews and impact evaluations and provide a graphical display of areas with strong, weak or non-existent evidence on the effects of development programs and initiatives. It's very cool and useful, but only available for a limited number of topics relevant to Youth, CED, HE, and ED.

- [USAID’s Development Experience Clearinghouse](https://www.usaid.gov/results-and-data/information-resources/development-experience-clearinghouse-dec) -- USAID's Development Experience Clearinghouse (DEC) is the largest online resource for USAID-funded technical and program documentation from more than 50 years of USAID's existence, with more than 155,000 documents available for viewing and electronic download. It's searchable: Use words or phrases, or perform a more advanced searches. You can also comment on documents, rate them, or vote on them to increase their usefulness to others.

- [USAID Program Evaluations](https://www.usaid.gov/results-and-data/progress-data/evaluations) -- "USAID uses evaluation findings to inform decisions, improve program effectiveness, be accountable to stakeholders, and support organizational learning. Strengthening evaluation and transparency are part of the USAID Forward reform agenda."

- [USAID’s Development Data Library](https://www.usaid.gov/data) -- The Development Data Library (DDL) is USAID’s public repository of Agency-funded, machine readable data. The DDL is part of USAID’s commitment to evidence-based programming and rigorous evaluation, while supporting the principles of the President’s Open Government Initiative. This website provides raw data rather than the analysis or conclusions made from data.




