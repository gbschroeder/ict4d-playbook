---
title: Field Guide to mobile data collection
---


___



##### Contents

- [Crash course in mobile data collection](#crash-course-in-mobile-data-collection)
	- [Who owns mobile data and m&e](#who-owns-mobile-data-and-m&e)
	- [Don't start with technology as the solution](#problems-and-solutions-as-external-from-the-technology)
	- [Technology last exercise](#the-mobile-data-mindset)
	- [Where to start](#custom-built-or-out-of-the-box)
	- [Should we build something?](#mobile-data-collection-questions)
- [12 steps to mobile data collection](#12-steps-to-mobile-data-collection)
- [Tips for successful mobile data collection for Volunteers](tips-for-successful-mobile-data-collection-for-volunteers)
- [Going forward](#going-forward)




___

# Crash course in mobile data collection

As a Peace Corps Volunteer, you use the tools available to you in order to have the most positive impact that you can during your service. You work with your communities to develop projects, action plans, and frameworks to solve the challenges they face.

In tackling these challenges, it is critical to know what's been done, to record what you're doing, to elicit feedback, to gather stories, and to better understand the ongoing impact of your efforts. 

Mobile data collection allows Peace Corps Volunteers to adopt a real-time, feedback-oriented, documented approach to their projects and activities. It benefits from the tremendous advantages and opportunities that smartphones and connectivity offer over paper & pencil surveys and record-keeping. Now, we have the opportunity to record more information, to analyze it in real-time, to mix and mash it with other datasets, to report on impact in ways previously unimaginable, and for our efforts to be tethered to evidence.

It enables our service to be oriented towards impact, and for us as Volunteers to act as mature, engaged, and impactful development professionals that use data to guide our decision-making.



## Who owns mobile data and M&E?

**First**—no single Peace Corps office, personnel role or title, manual, process, framework, or working group speaks for all things mobile data and monitoring & evaluation (M&E). The responsibility of intelligent approaches towards data, project management, feedback cycles, implementation, and reporting require expertise and insight from many different domains of knowledge and experience. It's easy to be overwhelmed by the intracacies of software, logframes, project frameworks, data integrity, the VRT, etc. **Don't be overwhelmed! There are folks all around you who are willing to help!**

**Second**—in the same vein, mobile tech **does not** equal a mobile VRF/VRT. This comes up time and time again, "well, just make the VRF mobile and we don't need to think about this anymore..." Sadly, it's not that simple. Happily, it's useful to think of opportunities to use technologies (or ICTs more generally) in our Peace Corps work as akin 'The Force' like in Star Wars. "...it surrounds us, it penetrates us, it binds us together." And it can also be used well and in strategic, simplified ways, or can be complex, complicated, and created by the Empire (the analogy falls apart a little at the end. But just barely.)

**Third**—it should never be about the technology. Seriously. Even when thinking about something data-heavy and complicated like mobile data collection, you should always take a step back and remember that **technology isn't the thing**, it's **the thing that allows you to do the thing**.

OK -- now that the caveats are out of the way, let's get started...



## Don't start with technology as the solution

A smartphone is not going to magically solve every challenge that your community faces, nor that you face in collecting data and becoming more informed through data for decision-making. There are no free lunches.

Using data, using smartphones, leveraging data that can easily (and with more difficulty) be collected are simpyly **mechanisms** or **tools** to help your community on their journey. Remember your Peace Corps training -- and remember that your goal here is to make the technology and the processes and the information work for the people—not the other way around!



## Technology last exercise

One helpful exercise before even beginning to sort through the links and resources below is to define what you're wanting to do *without* invoking the technology. Why do this? One, because it helps to ensure you've got a clearly articulated objective laid out ahead of you. Two, it's actually kind of difficult.

An example -- maybe you want to "create a map of all the bednets that are distributed within my community." Great! But let's think about this -- why do we want to create a map of this? What are we missing?

> "...so that we can see where there are unequal distributions of the nets and correct for that on an ongoing basis..." Better, but not perfect. Maps don't do that magically -- we need to think about the data behind the map, and connect that to the lessons learned from that, and connect these two with our mapping platform as the vehicle to move us from point A to point B.

> "Our team would like to correct for unequal distributions of bednets across our community in as real-time as possible." Ahhh. Doesn't that feel better? We know what we want, and we know what success is. NOW, we just get to add the tool that we'll use to achieve that -- "...by using an easily accessible and editable web-map that is informed by a database that is updated by data entry via mobile data collection..."

Remember, it's not all apps and forms and photos and GPS coordinates. At the end of the day, what Peace Corps wants, what we've always wanted, is to be good ambassadors to our communities, for our communities, and to provide value in our service (goals 2,3, and 1, respectively.)



## Where to start

Just because something is an app doesn't mean that it's going to work, that someone should use it, or that you should build a program around it. It's important to really think through your project, your approach, and your resource, *prior* to launching a full-scale mobile M&E (monitoring & evaluation) effort. Furthermore, there can be real costs and risks associated with collecting data -- even something that might be perceived at first glance as innocuous. Even demographic data such as a name, a person's gender, or where they're from can represent sensitive data that must if leaked or released could put that persons life or family in jeopardy.

There are tradeoffs in everyhing, and no solution is perfect.

Sometimes a smartphone app is not the way to go on a project (for lots of reasons). Maybe one platform is more user friendly but costs more, whereas another platform is free but is incredidbly clunky to build on.



## Should we build something?

An important consideration that one should be thinking about here is the extent to which platforms/apps/systems can be customized or tailored to fit our purposes. It's reasonable to think that if Peace Corps has actually bought/built something, then we should be able to extend or repurpose that thing to suit our needs in a cost-effective manner. And this is absolutely true. You should adopt a 'start where you are, use what you have, do what you can' approach. But be warned that just because something *can* do something does not mean that you should build your project around that platform's abilitity to actually *do* that thing. There are always tradeoffs involved, and it might well be that your customization at the end of the day requires significantly more investment than simply 'buying something off the shelf.'

Case in point -- Microsoft SharePoint is used by a lot of organizations to manage company intranets. Peace Corps is one of them. Can it be said that SharePoint can collect data? Yes. Can it work on a smartphone? Technically, yes. Can you set up forms, permissions, and different workspaces for different groups? Yes, yes, and yes. So it's perfect, right? Not exactly. There's not a single major international development organization that I know of that uses SharePoint as a back-end for their data collection. Why not? Simple -- it wasn't built to do that. While those answers are all technically yes, the hypothetical and the reality of those 'yes'es are crossed only by an ocean of deep investments in time, money, and effort.

Also remember that there are similar systems `to think about but aren't built for mobile data collection per se, but that you might hear about within a Peace Corps context. So a line of questioning around tradeoffs should be going through your mind anytime someone at Peace Corps says, "Well can't we just do what you want with..." and they say: "VRF, VRT, Microsoft SharePoint, Microsoft CRM, PCLive, PCMedics, VLMT, Tableau, Drupal, Wordpress, Moodle, Qualtrics, SurveyMonkey, Google Sheets, Google Forms, BaseCamp, Trello, SalesForce, SMS or text messaging, Facebook (I've heard this), Yammer (this one too), And countless others...)

So, what **are** the questions you should ask? There are many. Take a deep breath...



___



# 12 steps to mobile data collection

We've got you covered. Check out the [12 steps to mobile data collection] questions checklist to ensure that you're thinking through the issues that you might encounter along the way. Remember, an ounce of prevention is worth a pound of treatment, and so although it might seem laborious to look through some of these things -- they are borne out of experience and so you'll be doing yourself a favor by starting to address them as early as possible.

If this is overwhelming, that's ok! This isn't easy. We are talking about the intersections of international development, technology, and government. I hope you weren't thinking that would be easy. Alas, there are many organizations to learn from, and many efforts have been underway for years that we can learn from. To start you on your journey, I would recommend these starter apps and platforms (not exhaustive by any means, but a good start to see tradeoffs):



___



# Tips for successful mobile data collection for Volunteers


## Gabriel's off-the-cuff tips

- Remember that mobile data isn't magical, it should simply: **substitute**, **augment**, and **modify**
- It's important to remember that we don't know what we don't know.
- Start as simply as possible (but not simpler[^1]) -- country, project id, employee id, lat/long
- When we add 3 more people, it adds 10 units of confusion.
- Reporting -- is it a SQL backend, is it a PDF, is it Excel?
- Start with each project getting their own database.
- Start with each project having their own design workshop: think through report definitions, for example...
- Each project has their own reports -- reporting to donor and to use to track performance and to change activities.
- Don't start with global dashboards -- eventually there *will* be a global dashboard, but in the beginning it's important to think through data collection, data collection culture, data use culture at the project level. Once done, sustainable, consistent, then to global dashboards. **Without good data at the local level, we can't move to global data**.
- Core mantra is simplicity and focus.
- When in doubt, think only about the project, performance, impact data.
- Minimize the data that you are collecting -- even within that. What are the core indicators that we need to collect, and then forget about everything else.
- Standard business process -- how to use data, how to input data, etc...
- Think through measuring output, outcome, impact...not just outputs.
- Remember that good evaluation is:
	- Rigorous
	- Efficient
	- Ethical
	- Proportionate
	- Appropriate
	- Consistent
	- Authentic



## Monitoring & evaluation mistakes

### The Top Three Monitoring and Evaluation Mistakes Experienced NGOs Make
1. Using the same indicators they’ve always used, even as projects change
2. Too much evaluation, not enough monitoring
3. Leaving M&E up to the M&E team

### The Top Three M&E Mistakes New NGOs make
1. Choosing really great indicators that are nearly impossible to measure
2. Confusing a program with an RCT
3. Focusing on the donor’s data needs when choosing indicators

### The Top Four M&E Mistakes Everyone Makes
1. Too many indicators
2. Not focusing on data use
3. Too many process indicators, not enough impact indicators
4. The [IKEA effect](https://en.wikipedia.org/wiki/IKEA_effect) -- we built it so it must be awesome.



## A real checklist for thinking through ICTs in M&E

Moving more specifically into the ICT components, I *love* this checklist from Raftree and Bamberger[^2] -- 

1. Develop a quality M&E plan
2. Ensure design validity
3. Determine whether and how new ICTs can add value to an M&E plan
4. Select or assemble the right combination of Ict and M&E tools
5. Adapt and test the process with different audiences and stakeholders
6. Be aware of differing levels of access and inclusion
7. Understand motivation to participate in M&E activities
8. Ensure privacy and protection
9. Try to identify potential unintended consequences
10. Build local capacity
11. Measure what matters
12. Use and share M&E information effectively


___



# Going Forward

When you're ready to starting poking around, head over to the [Technology for Monitoring & Evaluation Resources](/technology-for-monitoring-&-evaluation/) page to check out the [Platforms and Apps](/technology-for-monitoring-&-evaluation/) section to get a sense for the various setups and configurations. I'll keep this updated as new developments occur.

...and this is before I even *start* to talk about SMS-exclusive setups like Twillio and FrontlineSMS. Hang tight for those...

This is just to get you started.

[1]: [Einsterin, obviously -- but actually Roger Sessions](http://quoteinvestigator.com/2011/05/13/einstein-simple/)
[2]: [ITAD - Monitoring and Evaluation in a Tech-Enabled World (Raftree, Bamberger, September 2014)](https://www.rockefellerfoundation.org/report/emerging-opportunities-monitoring/)